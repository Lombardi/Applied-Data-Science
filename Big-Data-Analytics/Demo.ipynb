{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml import feature, regression, Pipeline, classification\n",
    "from pyspark.sql import functions as fn, Row\n",
    "from pyspark import sql\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert back to spark for encoding pipeline ##\n",
    "flights_df_clean = spark.read.csv('flights_clean.csv', header = True).drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+---------------+\n",
      "|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|\n",
      "+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+---------------+\n",
      "|    1|  1|          4|     OO|         5460|     N583SW|           RDD|                SFO|            Morning|        Delayed|\n",
      "+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check to make sure it made it okay ##\n",
    "flights_df_clean.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE PIPELINE ##\n",
    "\n",
    "categorical_cols = ['DAY', 'MONTH', 'DAY_OF_WEEK', 'AIRLINE','FLIGHT_NUMBER','TAIL_NUMBER','ORIGIN_AIRPORT',\n",
    "                    'DESTINATION_AIRPORT','SCHEDULED_DEPARTURE']\n",
    "\n",
    "label_indexer = [feature.StringIndexer(inputCol = \"DEPARTURE_DELAY\",\n",
    "                                     outputCol = \"label\", handleInvalid = \"skip\")]\n",
    "\n",
    "indexers = [feature.StringIndexer(inputCol = column, \n",
    "                                  outputCol = \"{0}_index\".format(column), handleInvalid = \"skip\")\n",
    "            for column in categorical_cols\n",
    "           ]\n",
    "\n",
    "encoders = [feature.OneHotEncoder(dropLast=False, inputCol = indexer.getOutputCol(),\n",
    "                                         outputCol = \"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "          for indexer in indexers\n",
    "           ]\n",
    "\n",
    "assembler = [feature.VectorAssembler(inputCols = [encoder.getOutputCol() for encoder in encoders],\n",
    "                                     outputCol = \"features\")\n",
    "             ]\n",
    "\n",
    "# Build it and fit it to the dataset #\n",
    "\n",
    "flights_pipe = Pipeline(stages=indexers + label_indexer + encoders +assembler)\n",
    "preprocessing_model=flights_pipe.fit(flights_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the dataset using the pipeline to prepare it for training the model #\n",
    "\n",
    "flights_transformed = preprocessing_model.transform(flights_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+\n",
      "|features                                                                                |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "|(11659,[14,38,44,52,2403,10643,11276,11340,11654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(11659,[14,38,44,56,2154,7076,11026,11349,11654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|(11659,[14,38,44,53,6373,10636,11070,11376,11654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(11659,[14,38,44,49,127,6890,11023,11352,11654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |\n",
      "|(11659,[14,38,44,55,3335,7662,11108,11337,11654],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the features column to make sure everything encoded #\n",
    "\n",
    "flights_transformed.select('features').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a training, validation, and test split #\n",
    "training_df, validation_df, testing_df = flights_transformed.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "\n",
    "# Train the logistic regression model, manually passing it the optimized parameters #\n",
    "lr = classification.LogisticRegression(regParam = 0.01,\n",
    "                                      elasticNetParam = 0.5, maxIter = 10, featuresCol='features',labelCol='label')\n",
    "\n",
    "lr_model = lr.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---+-------------+-----------+--------------+-------------------+-------------------+-------+\n",
      "|DAY_OF_WEEK|MONTH|DAY|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|AIRLINE|\n",
      "+-----------+-----+---+-------------+-----------+--------------+-------------------+-------------------+-------+\n",
      "|          7|    4| 28|         1315|     N922EV|           LGA|                SFO|            Evening|     AA|\n",
      "+-----------+-----+---+-------------+-----------+--------------+-------------------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in demo .csv, and make sure the values are correct #\n",
    "demo_df = spark.read.csv('demo.csv', header = True)\n",
    "demo_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input data using the preprocessing pipeline and display the features to make sure the LR model will\n",
    "# accept it #\n",
    "transformed_demo_df = preprocessing_model.transform(demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(11659,[5,36,47,5...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure it's encoded properly #\n",
    "transformed_demo_df.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------+\n",
      "|Probability                             |Prediction|\n",
      "+----------------------------------------+----------+\n",
      "|[0.5091047553125613,0.49089524468743884]|0.0       |\n",
      "+----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform the input data using the LR model and display the probability #\n",
    "\n",
    "lr_model.transform(transformed_demo_df).select('Probability','Prediction').show(1,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
